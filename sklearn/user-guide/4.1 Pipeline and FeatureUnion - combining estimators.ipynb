{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1.1. Pipeline: chaining estimators\n",
    "\n",
    "- **Pipeline** can be used to chain multiple estimators into one. \n",
    "- This is useful as there is often a fixed sequence of steps in processing the data\n",
    "    - for example feature selection, normalization and classification. \n",
    "\n",
    "Pipeline serves two purposes here:\n",
    "\n",
    "- **Convenience**: You only have to call fit and predict once on your data to fit a whole sequence of estimators.\n",
    "- **Joint parameter selection**: You can grid search over parameters of all estimators in the pipeline at once.\n",
    "\n",
    "Pipeline structure\n",
    "- All estimators in a pipeline, except the last one, must be transformers (i.e. must have a transform method). \n",
    "- The last estimator may be any type (transformer, classifier, etc.).\n",
    "\n",
    "## relevant modules\n",
    "- `sklearn.pipeline.Pipeline` - choose your own **key**\n",
    "- `sklearn.pipeline.make_pipeline` - automatically fills in a **key** for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.1.1. Usage - list of (key,value) pair\n",
    "- **key** = any string you want to name the step as\n",
    "- **value** = estimator object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('reduce_dim', PCA(copy=True, n_components=None, whiten=False)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from pprint import pprint\n",
    "estimators = [('reduce_dim', PCA()), ('svm', SVC())]\n",
    "clf = Pipeline(estimators)\n",
    "pprint(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `make_pipeline`, the names(keys) are filled in automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('binarizer', Binarizer(copy=True, threshold=0.0)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import Binarizer\n",
    "pipe = make_pipeline(Binarizer(), MultinomialNB()) \n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__getattribute__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_final_estimator',\n",
       " '_get_param_names',\n",
       " '_pairwise',\n",
       " '_pre_transform',\n",
       " 'classes_',\n",
       " 'decision_function',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'get_params',\n",
       " 'inverse_transform',\n",
       " 'named_steps',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'steps',\n",
       " 'transform']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(clf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reduce_dim', PCA(copy=True, n_components=None, whiten=False)),\n",
       " ('svm',\n",
       "  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('reduce_dim', PCA(copy=True, n_components=None, whiten=False))\n",
      "PCA(copy=True, n_components=None, whiten=False)\n"
     ]
    }
   ],
   "source": [
    "# the estimators of a pipeline are stored as a list in the \"steps\" attribute\n",
    "print clf.steps[0]\n",
    "print clf.named_steps['reduce_dim'] # dict form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False))\n",
      "svm\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print clf.steps[1]\n",
    "print clf.steps[1][0]\n",
    "print clf.steps[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('reduce_dim', PCA(copy=True, n_components=None, whiten=False)), ('svm', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters of the estimators in the pipeline can be accessed using the <estimator>__<parameter> syntax:\n",
    "clf.set_params(svm__C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is particularly important for doing grid searches:\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "params = dict(reduce_dim__n_components=[2, 5, 10],\n",
    "              svm__C=[0.1, 10, 100])\n",
    "grid_search = GridSearchCV(clf, param_grid=params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
